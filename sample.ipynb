{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a detailed explanation of the solution, please see the README.md file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a boto3 bedrock client. We can use this client to issue API calls to Generative AI models available in Bedrock.\n",
    "\n",
    "Note: You can replace the profile_name with the profile name that is configured on your developer environment that has access to Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "import json\n",
    "import boto3\n",
    "REGION_NAME = 'us-east-1'\n",
    "retry_config = Config(\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "session = boto3.Session(region_name=REGION_NAME, profile_name='default')\n",
    "bedrock_client = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        config=retry_config\n",
    "    )\n",
    "\n",
    "print(\"boto3 Bedrock client successfully created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a resuable function that uses the client we created above to call Claude 3 Sonnet model on Bedrock. We can pass prompt and temperature to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_bedrock_claude_3(prompt_text, temperature):\n",
    "    model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_text\n",
    "                        }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    body = json.dumps(body)\n",
    "    response = bedrock_client.invoke_model(\n",
    "            body=body, modelId=model_id\n",
    "        )\n",
    "    # Parse the response\n",
    "    response_lines = response['body'].readlines()\n",
    "    json_str = response_lines[0].decode('utf-8')\n",
    "    json_obj = json.loads(json_str)\n",
    "    result_text = json_obj['content'][0]['text']\n",
    "    \n",
    "    return {'role': 'assistant', 'content': result_text}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "# Ensure the Gemini API key is configured\n",
    "GEMINI_API_KEY = \"AIzaSyA5bnFCaT3L3oPjwVPUQ1f5u6Z65ilGorQ\"  # Replace with your actual API key\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "def call_gemini(prompt_text, temperature=0.7):\n",
    "    model_name = \"gemini-pro\"\n",
    "    \n",
    "    # Start a chat session with the Gemini model\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    chat_session = model.start_chat()\n",
    "    \n",
    "    # Send the message to the model\n",
    "    response = chat_session.send_message(prompt_text)\n",
    "    \n",
    "    # Parse the response\n",
    "    result_text = response.text\n",
    "    \n",
    "    return {'role': 'assistant', 'content': result_text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the access to Bedrock with a  sample api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using Claude 3 Sonnet model\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "prompt = \"Hello...\"\n",
    "\n",
    "# Call Bedrock and get the response\n",
    "response = call_bedrock_claude_3(prompt, 0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hello...\"\n",
    "\n",
    "response = call_gemini(prompt, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **DynamoDB and Redis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this architecture, we use an Amazon DynamoDB table to persistently store all the chat messages. We create one table called \"ChatHistory\" with \"UserId\" as the partition key and \"Timestamp\" as the sort key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating DynamoDB Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "TABLE_NAME = 'ChatHistory'\n",
    "\n",
    "# Initialize the DynamoDB client\n",
    "dynamodb = boto3.client('dynamodb', region_name=REGION_NAME)\n",
    "\n",
    "# Create a DynamoDB table\n",
    "def create_dynamodb_table():\n",
    "    table_name = TABLE_NAME\n",
    "    try:\n",
    "        response = dynamodb.create_table(\n",
    "            TableName=table_name,\n",
    "            KeySchema=[\n",
    "                {\"AttributeName\": \"UserId\", \"KeyType\": \"HASH\"},  # Partition key\n",
    "                {\"AttributeName\": \"Timestamp\", \"KeyType\": \"RANGE\"}  # Sort key\n",
    "            ],\n",
    "            AttributeDefinitions=[\n",
    "                {\"AttributeName\": \"UserId\", \"AttributeType\": \"S\"},  \n",
    "                {\"AttributeName\": \"Timestamp\", \"AttributeType\": \"S\"}, \n",
    "            ],\n",
    "            ProvisionedThroughput={\n",
    "                \"ReadCapacityUnits\": 5,\n",
    "                \"WriteCapacityUnits\": 5\n",
    "            }\n",
    "        )\n",
    "        print(f\"Creating table {table_name}...\")\n",
    "        dynamodb.get_waiter('table_exists').wait(TableName=table_name)\n",
    "        print(f\"Table {table_name} has been created.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "\n",
    "# Call the function to create the table \n",
    "create_dynamodb_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/anaconda3/envs/gemini-rag/lib/python3.12/site-packages (from pymongo) (2.6.1)\n",
      "Downloading pymongo-4.10.1-cp312-cp312-macosx_11_0_arm64.whl (943 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.1/943.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymongo\n",
      "Successfully installed pymongo-4.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'chat_history' is set up with indexes.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient, ASCENDING\n",
    "\n",
    "# MongoDB setup\n",
    "MONGO_URI = 'mongodb://localhost:27017/'\n",
    "DATABASE_NAME = 'chat_database'\n",
    "COLLECTION_NAME = 'chat_history'\n",
    "\n",
    "# Initialize the MongoDB client\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DATABASE_NAME]\n",
    "\n",
    "# Create a MongoDB collection with indexes\n",
    "def create_mongodb_collection():\n",
    "    try:\n",
    "        # Create collection (will automatically create it if it doesn't exist)\n",
    "        collection = db[COLLECTION_NAME]\n",
    "\n",
    "        # Create indexes for UserId and Timestamp\n",
    "        collection.create_index([('UserId', ASCENDING), ('Timestamp', ASCENDING)], name='user_timestamp_index')\n",
    "        print(f\"Collection '{COLLECTION_NAME}' is set up with indexes.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MongoDB collection: {e}\")\n",
    "\n",
    "# Call the function to create the collection\n",
    "create_mongodb_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we install redis python package that will allow us to read or write from the cache. \n",
    "\n",
    "Note: This sample assumes there's a Redis cache already created and you have access to the endpoint. You can use AWS Elasticache to easily create serverless Redis Caches. Please visit this url to learn more: https://aws.amazon.com/blogs/aws/amazon-elasticache-serverless-for-redis-and-memcached-now-generally-available/\n",
    "\n",
    "Note: If you are using Elasticache Redis Serverless, you have to run this sample from the same VPC as the cache is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block we create two handy functions to test the connection to Redis and DynamoDB. We will add some test data and try retrieving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved messages from Redis for test_user_redis:\n",
      "{'content': 'Hello from Redis!', 'timestamp': '2024-10-08T21:10:34.641450'}\n",
      "{'content': 'Hello from Redis!', 'timestamp': '2024-10-08T10:10:45.278309'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/km2fq0xs06g8b5nj2t36d5fw0000gn/T/ipykernel_78677/2352696017.py:29: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().isoformat()\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration for Redis and DynamoDB\n",
    "\n",
    "redis_host = \"localhost\"\n",
    "redis_port = 6379\n",
    "\n",
    "redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)\n",
    "\n",
    "\n",
    "# dynamodb_table = TABLE_NAME\n",
    "# aws_region = REGION_NAME\n",
    "\n",
    "# Initialize Redis client\n",
    "\n",
    "\n",
    "# Initialize DynamoDB client\n",
    "\n",
    "\n",
    "\n",
    "# Test function for Redis connection\n",
    "def test_redis_connection():\n",
    "    try:\n",
    "        # Add a test message to Redis\n",
    "        user_id = \"test_user_redis\"\n",
    "        message_text = \"Hello from Redis!\"\n",
    "        timestamp = datetime.utcnow().isoformat()\n",
    "        message = {\"content\": message_text, \"timestamp\": timestamp}\n",
    "        stack_key = f\"{user_id}:stack\"\n",
    "        redis_client.rpush(stack_key, json.dumps(message))\n",
    "\n",
    "        # Retrieve and print the messages\n",
    "        retrieved_messages = redis_client.lrange(stack_key, 0, -1)\n",
    "        print(f\"Retrieved messages from Redis for {user_id}:\")\n",
    "        for msg in retrieved_messages:\n",
    "            print(json.loads(msg))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Redis connection test: {e}\")\n",
    "\n",
    "# dynamodb_client = boto3.client('dynamodb', region_name=REGION_NAME)\n",
    "# # Test function for DynamoDB connection\n",
    "# def test_dynamodb_connection():\n",
    "#     try:\n",
    "#         # Add a test message to DynamoDB\n",
    "#         user_id = \"test_user_dynamodb\"\n",
    "#         message_text = \"Hello from DynamoDB!\"\n",
    "#         timestamp = datetime.utcnow().isoformat()\n",
    "#         dynamodb_client.put_item(\n",
    "#             TableName=TABLE_NAME,\n",
    "#             Item={\n",
    "#                 \"UserId\": {\"S\": user_id},\n",
    "#                 \"Timestamp\": {\"S\": timestamp},\n",
    "#                 \"Content\": {\"S\": message_text},\n",
    "#                 \"BatchId\": {\"N\": \"1\"}\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         # Query and print the messages\n",
    "#         response = dynamodb_client.query(\n",
    "#             TableName=dynamodb_table,\n",
    "#             KeyConditionExpression=\"UserId = :user\",\n",
    "#             ExpressionAttributeValues={\":user\": {\"S\": user_id}}\n",
    "#         )\n",
    "#         print(f\"Retrieved messages from DynamoDB for {user_id}:\")\n",
    "#         for item in response['Items']:\n",
    "#             print({\n",
    "#                 \"UserId\": item[\"UserId\"][\"S\"],\n",
    "#                 \"Timestamp\": item[\"Timestamp\"][\"S\"],\n",
    "#                 \"Content\": item[\"Content\"][\"S\"],\n",
    "#                 \"BatchId\": item[\"BatchId\"][\"N\"]\n",
    "#             })\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in DynamoDB connection test: {e}\")\n",
    "\n",
    "\n",
    "# Run the test functions\n",
    "test_redis_connection()\n",
    "# test_dynamodb_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved messages from MongoDB for test_user_mongodb:\n",
      "{'UserId': 'test_user_mongodb', 'Timestamp': '2024-10-08T09:13:21.382597', 'Content': 'Hello from MongoDB!', 'BatchId': 1}\n",
      "{'UserId': 'test_user_mongodb', 'Timestamp': '2024-10-08T10:11:04.475494', 'Content': 'Hello from MongoDB!', 'BatchId': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/km2fq0xs06g8b5nj2t36d5fw0000gn/T/ipykernel_78677/4062419268.py:12: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().isoformat()\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MongoDB client\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DATABASE_NAME]\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "# Test function for MongoDB connection\n",
    "def test_mongodb_connection():\n",
    "    try:\n",
    "        # Add a test message to MongoDB\n",
    "        user_id = \"test_user_mongodb\"\n",
    "        message_text = \"Hello from MongoDB!\"\n",
    "        timestamp = datetime.utcnow().isoformat()\n",
    "        \n",
    "        # Create the message document\n",
    "        message_doc = {\n",
    "            \"UserId\": user_id,\n",
    "            \"Timestamp\": timestamp,\n",
    "            \"Content\": message_text,\n",
    "            \"BatchId\": 1  # You can change this as needed\n",
    "        }\n",
    "        \n",
    "        # Insert the message into MongoDB\n",
    "        collection.insert_one(message_doc)\n",
    "\n",
    "        # Query and print the messages\n",
    "        retrieved_messages = list(collection.find({\"UserId\": user_id}))\n",
    "        print(f\"Retrieved messages from MongoDB for {user_id}:\")\n",
    "        for item in retrieved_messages:\n",
    "            print({\n",
    "                \"UserId\": item[\"UserId\"],\n",
    "                \"Timestamp\": item[\"Timestamp\"],\n",
    "                \"Content\": item[\"Content\"],\n",
    "                \"BatchId\": item[\"BatchId\"]\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error in MongoDB connection test: {e}\")\n",
    "\n",
    "# Call the function to test MongoDB connection\n",
    "test_mongodb_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purposes, we can also create two utility functions to completely cleanup data from Redis and DynamoDB. \n",
    "\n",
    "**Please note:** Use these functions with caution, only while testing. These can delete important data in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleared all data in the current Redis database.\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "def clear_all_redis_data(redis_host, redis_port, redis_password=None):\n",
    "    try:\n",
    "        # Connect to Redis\n",
    "        redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)\n",
    "        \n",
    "        # Flush all keys in the current database\n",
    "        redis_client.flushdb()\n",
    "        print(\"Successfully cleared all data in the current Redis database.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing Redis data: {e}\")\n",
    "\n",
    "\n",
    "# Call the function to clear all data in Redis\n",
    "clear_all_redis_data(redis_host, 6379)  # Remove password if not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleared 2 documents from MongoDB collection: chat_history\n"
     ]
    }
   ],
   "source": [
    "def clear_all_mongodb_data(database_name, collection_name):\n",
    "    # Initialize the MongoDB client\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[database_name]\n",
    "    collection = db[collection_name]\n",
    "    \n",
    "    try:\n",
    "        # Delete all documents in the collection\n",
    "        result = collection.delete_many({})\n",
    "        print(f\"Successfully cleared {result.deleted_count} documents from MongoDB collection: {collection_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing MongoDB data: {e}\")\n",
    "\n",
    "# Call the function to clear all data from the specified collection\n",
    "clear_all_mongodb_data(DATABASE_NAME, COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "def clear_all_dynamodb_data(table_name, aws_region):\n",
    "    dynamodb_client = boto3.client('dynamodb', region_name=aws_region)\n",
    "    dynamodb_resource = boto3.resource('dynamodb', region_name=aws_region)\n",
    "    table = dynamodb_resource.Table(table_name)\n",
    "    \n",
    "    try:\n",
    "        # Scan to get all items\n",
    "        response = table.scan()\n",
    "        items = response['Items']\n",
    "\n",
    "        # Use batch writer to delete items in batches\n",
    "        with table.batch_writer() as batch:\n",
    "            for item in items:\n",
    "                batch.delete_item(Key={\"UserId\": item['UserId'], \"Timestamp\": item['Timestamp']})\n",
    "        \n",
    "        print(f\"Successfully cleared all data from DynamoDB table: {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing DynamoDB data: {e}\")\n",
    "\n",
    "# Call the function to clear all data in DynamoDB\n",
    "clear_all_dynamodb_data(TABLE_NAME, REGION_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **Chat History Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every 20 messages in a user's chat, we summarize them using an LLM (Claude 3). The following code creates a simple summarization prompt and a function to call the LLM. You can modify the prompt for your particular use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_prompt = \"\"\"\n",
    "Given a history of chat messages, summarize the conversation between user and AI in to one paragraph of not more than 250 words.\n",
    "Summarize all user messages in to one paragraph and all AI messages in to another paragraph.\n",
    "User: \n",
    "AI: \n",
    "\n",
    "Message history:\n",
    "{conversation}\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "def summarize_chat_history(messages):\n",
    "    # Combine all user messages (20 messages are passed to this function at a time)\n",
    "    summary = \" \".join([str(msg) for msg in messages])\n",
    "    # Generate the prompt for summarization\n",
    "    prompt = summarize_prompt.format(conversation=summary)\n",
    "    # Call the Bedrock model to generate the summary\n",
    "    response = call_gemini(prompt, 0.7)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the ChatManager class which handles the new message workflow, the summarization and chat history retrieval workflows.\n",
    "\n",
    "Please read inline comments for explanation of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import boto3\n",
    "import json\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "\n",
    "class ChatManager:\n",
    "    def __init__(self, redis_host, redis_port, dynamodb_table, region):\n",
    "        # Connect to Redis\n",
    "        self.redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True, ssl=True)\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        # Set up DynamoDB client and table\n",
    "        self.dynamodb_client = boto3.client('dynamodb', region_name=region)\n",
    "        self.dynamodb_resource = boto3.resource('dynamodb', region_name=region)\n",
    "        self.dynamodb_table = dynamodb_table\n",
    "        self.region = region\n",
    "\n",
    "    def count_messages_with_batch(self, stack_key, batch_id):\n",
    "        \"\"\"\n",
    "        Count the number of messages in the specified stack that have the given batch_id.\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        # Retrieve all messages from the Redis stack\n",
    "        messages = self.redis_client.lrange(stack_key, 0, -1)\n",
    "\n",
    "        # Count messages with the specified batch_id\n",
    "        for msg in messages:\n",
    "            message = json.loads(msg)\n",
    "            if message[\"batch_id\"] == batch_id:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def handle_new_message(self, user_id, message_text):\n",
    "        with self.lock:\n",
    "            # Define keys for Redis\n",
    "            stack_key = f\"{user_id}:stack\" # Stores individual messages for a particular user\n",
    "            batch_id_key = f\"{user_id}:batch_id\" # Stores the current batch ID for a user\n",
    "            \n",
    "            # Retrieve the current batch ID from Redis, or initialize it\n",
    "            batch_id = self.redis_client.get(batch_id_key)\n",
    "            if batch_id is None:\n",
    "                batch_id = 1\n",
    "            else:\n",
    "                batch_id = int(batch_id)\n",
    "\n",
    "            # Create a new message dictionary with a timestamp\n",
    "            timestamp = datetime.now().isoformat()\n",
    "            message = {\"batch_id\": batch_id, \"content\": message_text, \"timestamp\": timestamp}\n",
    "            \n",
    "            # Add the new message to the cache stack for the user. When the stack reaches 20 messages, a summary is created.\n",
    "            self.redis_client.rpush(stack_key, json.dumps(message))\n",
    "\n",
    "            # Persist the message to DynamoDB\n",
    "            self.dynamodb_client.put_item(\n",
    "                TableName=self.dynamodb_table,\n",
    "                Item={\n",
    "                    \"UserId\": {\"S\": user_id},\n",
    "                    \"Timestamp\": {\"S\": timestamp},\n",
    "                    \"Content\": {\"S\": message_text},\n",
    "                    \"BatchId\": {\"N\": str(batch_id)}\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Check if the stack has 20 messages for the current batch ID\n",
    "            count = self.count_messages_with_batch(stack_key, batch_id)\n",
    "            if count == 4:\n",
    "                threading.Thread(target=self._create_summary, args=(user_id, batch_id)).start()\n",
    "                self.redis_client.set(batch_id_key, batch_id + 1)\n",
    "\n",
    "    def _create_summary(self, user_id, batch_id):\n",
    "        with self.lock:\n",
    "            # Retrieve all messages for the user with the specified batch ID\n",
    "            stack_key = f\"{user_id}:stack\"\n",
    "            all_messages = [json.loads(msg) for msg in self.redis_client.lrange(stack_key, 0, -1)]\n",
    "            messages = [msg for msg in all_messages if msg[\"batch_id\"] == batch_id]\n",
    "\n",
    "            # Create a summary of those messages\n",
    "            summary_content = summarize_chat_history(messages)\n",
    "            summary = {\"batch_id\": batch_id, \"content\": summary_content, \"count\": len(messages)}\n",
    "\n",
    "            # Store the summary in Redis\n",
    "            summary_key = f\"{user_id}:summary\"\n",
    "            self.redis_client.set(summary_key, json.dumps(summary))\n",
    "\n",
    "            # Gather all messages from the cache which have not been summarized yet\n",
    "            remaining_messages = [msg for msg in all_messages if msg[\"batch_id\"] != batch_id]\n",
    "\n",
    "            # Clear the stack and repopulate with the remaining messages\n",
    "            self.redis_client.delete(stack_key)\n",
    "            for msg in remaining_messages:\n",
    "                self.redis_client.rpush(stack_key, json.dumps(msg))\n",
    "\n",
    "    # Get the chat history for a user. This fetches the most recent summary and messages which are not summarized yet.\n",
    "    def get_chat_history(self, user_id):\n",
    "        \n",
    "\n",
    "        # Retrieve the summary for the user and add it to the history\n",
    "        summary_key = f\"{user_id}:summary\"\n",
    "        summary = self.redis_client.get(summary_key)\n",
    "        history = []\n",
    "        \n",
    "        if summary is not None:\n",
    "            history.append(json.loads(summary))\n",
    "\n",
    "        # Retrieve all messages from the Redis stack which have not been summarized. This batch will be summarized when it reaches 20 messages.\n",
    "        # Combine the remaining messages with the summary\n",
    "        stack_key = f\"{user_id}:stack\"\n",
    "        remaining_messages = [json.loads(msg) for msg in self.redis_client.lrange(stack_key, 0, -1)]\n",
    "        history.extend(remaining_messages)\n",
    "\n",
    "        return history\n",
    "\n",
    "    # We use this method to load the last 20 messages for a user from DynamoDB and populate the Redis cache. This is useful when the cache is reset or when the application is restarted.\n",
    "    def load_messages_from_dynamodb(self, user_id):\n",
    "       \n",
    "        table = self.dynamodb_resource.Table(TABLE_NAME)\n",
    "        \n",
    "        # Query the table with a limit of 20 items\n",
    "        response = table.query(\n",
    "            KeyConditionExpression=Key('UserId').eq(user_id),\n",
    "            Limit=20,\n",
    "            ScanIndexForward=False # Retrieve in descending order of the sort key: Timestamp\n",
    "        )\n",
    "\n",
    "        # Reset Redis state and populate messages\n",
    "        stack_key = f\"{user_id}:stack\"\n",
    "        summary_key = f\"{user_id}:summary\"\n",
    "        self.redis_client.delete(stack_key)\n",
    "        self.redis_client.delete(summary_key)\n",
    "        \n",
    "        # Rehydrate redis cache\n",
    "        for item in reversed(response['Items']):\n",
    "            print(\"Reloading:\"+str(item))\n",
    "            message = {\"batch_id\": int(item['BatchId']), \"content\": item['Content'], \"timestamp\": item['Timestamp']}\n",
    "            self.redis_client.rpush(stack_key, json.dumps(message))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "class ChatManager:\n",
    "    def __init__(self, redis_host, redis_port, mongo_uri, database_name, collection_name):\n",
    "        # Connect to Redis\n",
    "        self.redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        # Set up MongoDB client, database, and collection\n",
    "        self.mongo_client = MongoClient(mongo_uri)\n",
    "        self.db = self.mongo_client[database_name]\n",
    "        self.collection = self.db[collection_name]\n",
    "\n",
    "    def count_messages_with_batch(self, stack_key, batch_id):\n",
    "        \"\"\"\n",
    "        Count the number of messages in the specified stack that have the given batch_id.\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        # Retrieve all messages from the Redis stack\n",
    "        messages = self.redis_client.lrange(stack_key, 0, -1)\n",
    "\n",
    "        # Count messages with the specified batch_id\n",
    "        for msg in messages:\n",
    "            message = json.loads(msg)\n",
    "            if message[\"batch_id\"] == batch_id:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def handle_new_message(self, user_id, message_text):\n",
    "        with self.lock:\n",
    "            # Define keys for Redis\n",
    "            stack_key = f\"{user_id}:stack\"  # Stores individual messages for a particular user\n",
    "            batch_id_key = f\"{user_id}:batch_id\"  # Stores the current batch ID for a user\n",
    "            \n",
    "            # Retrieve the current batch ID from Redis, or initialize it\n",
    "            batch_id = self.redis_client.get(batch_id_key)\n",
    "            if batch_id is None:\n",
    "                batch_id = 1\n",
    "            else:\n",
    "                batch_id = int(batch_id)\n",
    "\n",
    "            # Create a new message dictionary with a timestamp\n",
    "            timestamp = datetime.now().isoformat()\n",
    "            message = {\"batch_id\": batch_id, \"content\": message_text, \"timestamp\": timestamp}\n",
    "            \n",
    "            # Add the new message to the cache stack for the user. When the stack reaches 20 messages, a summary is created.\n",
    "            self.redis_client.rpush(stack_key, json.dumps(message))\n",
    "\n",
    "            # Persist the message to MongoDB\n",
    "            message_doc = {\n",
    "                \"UserId\": user_id,\n",
    "                \"Timestamp\": timestamp,\n",
    "                \"Content\": message_text,\n",
    "                \"BatchId\": batch_id\n",
    "            }\n",
    "            self.collection.insert_one(message_doc)\n",
    "\n",
    "            # Check if the stack has 20 messages for the current batch ID\n",
    "            count = self.count_messages_with_batch(stack_key, batch_id)\n",
    "            if count == 20:  # Check if the stack has 20 messages\n",
    "                threading.Thread(target=self._create_summary, args=(user_id, batch_id)).start()\n",
    "                self.redis_client.set(batch_id_key, batch_id + 1)\n",
    "\n",
    "    def _create_summary(self, user_id, batch_id):\n",
    "        with self.lock:\n",
    "            # Retrieve all messages for the user with the specified batch ID\n",
    "            stack_key = f\"{user_id}:stack\"\n",
    "            all_messages = [json.loads(msg) for msg in self.redis_client.lrange(stack_key, 0, -1)]\n",
    "            messages = [msg for msg in all_messages if msg[\"batch_id\"] == batch_id]\n",
    "\n",
    "            # Create a summary of those messages\n",
    "            summary_content = summarize_chat_history(messages)\n",
    "            summary = {\"batch_id\": batch_id, \"content\": summary_content, \"count\": len(messages)}\n",
    "\n",
    "            # Store the summary in Redis\n",
    "            summary_key = f\"{user_id}:summary\"\n",
    "            self.redis_client.set(summary_key, json.dumps(summary))\n",
    "\n",
    "            # Gather all messages from the cache which have not been summarized yet\n",
    "            remaining_messages = [msg for msg in all_messages if msg[\"batch_id\"] != batch_id]\n",
    "\n",
    "            # Clear the stack and repopulate with the remaining messages\n",
    "            self.redis_client.delete(stack_key)\n",
    "            for msg in remaining_messages:\n",
    "                self.redis_client.rpush(stack_key, json.dumps(msg))\n",
    "\n",
    "    # Get the chat history for a user. This fetches the most recent summary and messages which are not summarized yet.\n",
    "    def get_chat_history(self, user_id):\n",
    "        # Retrieve the summary for the user and add it to the history\n",
    "        summary_key = f\"{user_id}:summary\"\n",
    "        summary = self.redis_client.get(summary_key)\n",
    "        history = []\n",
    "        \n",
    "        if summary is not None:\n",
    "            history.append(json.loads(summary))\n",
    "\n",
    "        # Retrieve all messages from the Redis stack which have not been summarized. This batch will be summarized when it reaches 20 messages.\n",
    "        # Combine the remaining messages with the summary\n",
    "        stack_key = f\"{user_id}:stack\"\n",
    "        remaining_messages = [json.loads(msg) for msg in self.redis_client.lrange(stack_key, 0, -1)]\n",
    "        history.extend(remaining_messages)\n",
    "\n",
    "        return history\n",
    "\n",
    "    # Load the last 20 messages for a user from MongoDB and populate the Redis cache.\n",
    "    def load_messages_from_mongodb(self, user_id):\n",
    "        # Query the collection with a limit of 20 items\n",
    "        messages = list(self.collection.find({\"UserId\": user_id}).sort(\"Timestamp\", -1).limit(20))\n",
    "\n",
    "        # Reset Redis state and populate messages\n",
    "        stack_key = f\"{user_id}:stack\"\n",
    "        summary_key = f\"{user_id}:summary\"\n",
    "        self.redis_client.delete(stack_key)\n",
    "        self.redis_client.delete(summary_key)\n",
    "        \n",
    "        # Rehydrate redis cache\n",
    "        for item in reversed(messages):\n",
    "            print(\"Reloading:\" + str(item))\n",
    "            message = {\"batch_id\": int(item['BatchId']), \"content\": item['Content'], \"timestamp\": item['Timestamp']}\n",
    "            self.redis_client.rpush(stack_key, json.dumps(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we instantiate the class. To demonstrate the new messages and summarization workflows, we load sample conversations. Please check sample_conversations.py for a sample chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# chat_manager = ChatManager(redis_host, redis_port, dynamodb_table, REGION_NAME)\n",
    "chat_manager = ChatManager(redis_host, redis_port, MONGO_URI, DATABASE_NAME, COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Sample Messages. Summarization worflow gets triggered when we load 20 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/km2fq0xs06g8b5nj2t36d5fw0000gn/T/ipykernel_78677/1929269648.py:47: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().isoformat()\n"
     ]
    }
   ],
   "source": [
    "from sample_conversation import conversation\n",
    "\n",
    "for c in conversation:\n",
    "    chat_manager.handle_new_message(\"user1\", str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fetch the chat history at this point and youll see that it fetches most recent messages which have not been summarized (because the batch did not reach count 20) and the most recent summary. Notice the bacth id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'batch_id': 1,\n",
      "  'content': {'content': '**User Messages:**\\n'\n",
      "                         'The user inquired about Amazon Web Services (AWS), '\n",
      "                         'its offerings, and popular services like EC2 and S3. '\n",
      "                         'They sought clarification on storage management, the '\n",
      "                         'differences between S3 and EBS, the functionality of '\n",
      "                         'Lambda, and the trigger events for Lambda functions. '\n",
      "                         'Additionally, the user was curious about the AWS '\n",
      "                         'Free Tier and its distinction from regular pricing '\n",
      "                         'plans.\\n'\n",
      "                         '\\n'\n",
      "                         '**AI Messages:**\\n'\n",
      "                         'The AI assistant provided detailed responses about '\n",
      "                         'AWS, including its definition as a cloud computing '\n",
      "                         'platform offering various services. It listed '\n",
      "                         'popular services like EC2, S3, Lambda, and RDS. The '\n",
      "                         'assistant explained the operation of EC2 as virtual '\n",
      "                         'servers for running applications. It clarified the '\n",
      "                         'storage options provided by AWS, emphasizing S3 for '\n",
      "                         'object storage and EBS for block storage. The '\n",
      "                         'assistant described Lambda as a serverless compute '\n",
      "                         'service that responds to events and scales '\n",
      "                         'automatically. It also gave examples of events that '\n",
      "                         'could trigger a Lambda function. Furthermore, the '\n",
      "                         'assistant explained the AWS Free Tier, highlighting '\n",
      "                         'that it offers limited access to services at no cost '\n",
      "                         'but subjects users to standard pricing when usage '\n",
      "                         'exceeds the specified limits.',\n",
      "              'role': 'assistant'},\n",
      "  'count': 20},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'user', 'content': 'Does AWS offer managed databases?'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.544163'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'assistant', 'content': 'Yes, AWS offers managed \"\n",
      "             'databases through services like RDS for relational databases and '\n",
      "             \"DynamoDB for NoSQL.'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.546360'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'user', 'content': 'What are the advantages of using \"\n",
      "             \"DynamoDB over traditional relational databases?'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.548547'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'assistant', 'content': 'DynamoDB is optimized for \"\n",
      "             'low-latency, high-throughput operations and automatically scales '\n",
      "             \"to meet the demands of your application.'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.550782'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'user', 'content': 'How does RDS simplify database \"\n",
      "             \"management?'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.551727'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'assistant', 'content': 'RDS automates tasks like \"\n",
      "             'backups, software patching, and scaling, allowing you to focus '\n",
      "             \"on building your application instead of managing the database.'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.553955'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'user', 'content': 'What is AWS IAM, and why is it \"\n",
      "             \"important?'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.555263'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'assistant', 'content': 'AWS Identity and Access \"\n",
      "             'Management (IAM) enables secure access to AWS services by '\n",
      "             'allowing you to create and manage users, groups, and '\n",
      "             \"permissions.'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.556411'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'user', 'content': 'What are security best practices \"\n",
      "             \"for AWS IAM?'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.557743'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'assistant', 'content': 'Best practices include using \"\n",
      "             'strong passwords, multi-factor authentication, least privilege '\n",
      "             \"access, and regular audits of permissions.'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.559509'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'user', 'content': 'Can you explain how multi-factor \"\n",
      "             \"authentication works in IAM?'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.562246'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'assistant', 'content': 'Multi-factor authentication \"\n",
      "             'adds an extra layer of security by requiring both a password and '\n",
      "             \"a temporary code from a trusted device like a mobile app.'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.563924'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'user', 'content': 'What are some ways to optimize AWS \"\n",
      "             \"costs?'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.566421'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'assistant', 'content': 'Cost optimization can be \"\n",
      "             'achieved by using reserved instances, spot instances, the right '\n",
      "             \"storage tier, and rightsizing your resources.'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.569321'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'user', 'content': 'What are spot instances, and how \"\n",
      "             \"are they useful?'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.571428'},\n",
      " {'batch_id': 2,\n",
      "  'content': \"{'role': 'assistant', 'content': 'Spot instances are spare EC2 \"\n",
      "             'capacity offered at a discount. They are ideal for flexible '\n",
      "             \"workloads that can handle interruptions.'}\",\n",
      "  'timestamp': '2024-10-08T10:17:10.573406'},\n",
      " {'batch_id': 2,\n",
      "  'content': '{\\'role\\': \\'user\\', \\'content\\': \"Can you explain what '\n",
      "             '\\'rightsizing\\' resources means?\"}',\n",
      "  'timestamp': '2024-10-08T10:17:10.576073'},\n",
      " {'batch_id': 2,\n",
      "  'content': '{\\'role\\': \\'assistant\\', \\'content\\': \"Rightsizing involves '\n",
      "             'adjusting the size of your resources to match your workload '\n",
      "             \"requirements, ensuring you're not over-provisioning or \"\n",
      "             'under-utilizing.\"}',\n",
      "  'timestamp': '2024-10-08T10:17:10.578754'}]\n"
     ]
    }
   ],
   "source": [
    "history = chat_manager.get_chat_history(\"user1\")\n",
    "pprint.pprint(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a loop to create a simple chatbot. On every new message, we first fetch the history, combine it with the question and send it to the LLM to get a response. Once we get a response, we add the user's message and LLM's response to Redis and DynamoDB accordingly using handle_new_message function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'This conversation covers various topics related to Amazon Web Services (AWS), including its offerings, popular services, managed databases, database management, security best practices, cost optimization, and resource optimization.'}\n",
      "{'role': 'assistant', 'content': 'The conversation covers a wide range of topics related to AWS services, including managed databases, DynamoDB, RDS, IAM, cost optimization, and resource optimization. Here is a summary of the discussion:\\n\\n- **Managed databases**: AWS offers a range of managed database services, including DynamoDB, RDS, and Aurora. These services make it easy to set up, manage, and scale databases without the need for specialized expertise.\\n- **DynamoDB**: DynamoDB is a scalable, low-latency NoSQL database service that is designed for high-performance applications. It offers automatic scaling, high availability, and built-in security features.\\n- **RDS**: RDS is a fully managed relational database service that supports a variety of database engines, including MySQL, PostgreSQL, and Oracle. It offers automated backups, high availability, and performance monitoring.\\n- **IAM**: IAM is a cloud-based identity and access management service that helps you securely control access to your AWS resources. It allows you to create users, groups, and roles, and to assign permissions to these entities.\\n- **Cost optimization**: AWS offers a variety of tools and services to help you optimize your AWS costs. These tools can help you identify and eliminate unused resources, optimize your instance types and storage tiers, and take advantage of discounts and pricing programs.\\n- **Resource optimization**: Rightsizing your resources is important to ensure that you are using the appropriate amount of resources for your workload. AWS provides a variety of tools and services to help you rightsize your resources, including the EC2 Instance Advisor and the Auto Scaling service.\\n\\nOverall, the conversation provides a comprehensive overview of AWS services and best practices.'}\n",
      "{'role': 'assistant', 'content': 'I am sorry, but the provided context does not have the answer to your question. The context focuses on a discussion about AWS services, database management, and optimization strategies without any mention of \"Hello.\"'}\n",
      "{'role': 'assistant', 'content': 'I am sorry, but the provided context does not have the answer to your question. The context focuses on a discussion about AWS services, database management, and optimization strategies without any mention of \"Hello.\"'}\n",
      "{'role': 'assistant', 'content': 'The main AWS services discussed in the conversation are:\\n- Managed databases, including DynamoDB, RDS, and Aurora\\n- Identity and Access Management (IAM)\\n- Cost optimization tools and services\\n- Resource optimization tools and services, including the EC2 Instance Advisor and the Auto Scaling service'}\n",
      "{'role': 'assistant', 'content': '- **Managed databases**: AWS offers a range of managed database services, including DynamoDB, RDS, and Aurora. These services make it easy to set up, manage, and scale databases without the need for specialized expertise.\\n- **IAM**: IAM is a cloud-based identity and access management service that helps you securely control access to your AWS resources. It allows you to create users, groups, and roles, and to assign permissions to these entities.\\n- **Cost optimization**: AWS offers a variety of tools and services to help you optimize your AWS costs. These tools can help you identify and eliminate unused resources, optimize your instance types and storage tiers, and take advantage of discounts and pricing programs.\\n- **Resource optimization**: Rightsizing your resources is important to ensure that you are using the appropriate amount of resources for your workload. AWS provides a variety of tools and services to help you rightsize your resources, including the EC2 Instance Advisor and the Auto Scaling service.'}\n"
     ]
    }
   ],
   "source": [
    "question_prompt = \"\"\"\n",
    "Given a question and chat history, answer the question in the context of the conversation.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    question = input()\n",
    "    message = {\"role\":\"user\", \"content\": question}\n",
    "    history = str(chat_manager.get_chat_history(\"user1\"))\n",
    "    prompt = question_prompt.format(chat_history=history, question=question)\n",
    "    response = call_gemini(prompt, 0.7)\n",
    "    chat_manager.handle_new_message(\"user1\", str(message))\n",
    "    chat_manager.handle_new_message(\"user1\", str(response))\n",
    "    print(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can now see the chat history again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'batch_id': 2,\n",
      "  'content': {'content': '**User Messages:**\\n'\n",
      "                         \"The user inquired about AWS's offerings, inquiring \"\n",
      "                         'specifically about managed databases, the advantages '\n",
      "                         'of DynamoDB over relational databases, the benefits '\n",
      "                         'of using RDS for database management, the purpose '\n",
      "                         'and significance of AWS IAM, best practices for IAM '\n",
      "                         'security, the functionality of multi-factor '\n",
      "                         'authentication, strategies for optimizing AWS costs, '\n",
      "                         'the nature of spot instances, the concept of '\n",
      "                         'rightsizing resources, and the overall topic of the '\n",
      "                         'conversation.\\n'\n",
      "                         '\\n'\n",
      "                         '**AI Messages:**\\n'\n",
      "                         \"The AI provided informative responses to the user's \"\n",
      "                         \"queries, explaining AWS's managed database services, \"\n",
      "                         'the scalability and low latency of DynamoDB, the '\n",
      "                         'automated management capabilities of RDS, the role '\n",
      "                         'of IAM in securing AWS resources, the importance of '\n",
      "                         'implementing strong passwords, multi-factor '\n",
      "                         'authentication, least privilege access, and regular '\n",
      "                         'permission audits, the process of multi-factor '\n",
      "                         'authentication, the benefits of cost optimization '\n",
      "                         'through techniques like reserved and spot instances, '\n",
      "                         'storage tier selection, and rightsizing, the '\n",
      "                         'definition and utility of spot instances, the '\n",
      "                         'concept of rightsizing resources to align with '\n",
      "                         'workload requirements, and the diverse topics '\n",
      "                         'covered in the conversation, ranging from AWS '\n",
      "                         'services to database management and optimization.',\n",
      "              'role': 'assistant'},\n",
      "  'count': 20},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'user', 'content': 'Give me a summary of everything \"\n",
      "             \"that is discussed here'}\",\n",
      "  'timestamp': '2024-10-08T21:20:48.547884'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'assistant', 'content': 'The conversation covers a wide \"\n",
      "             'range of topics related to AWS services, including managed '\n",
      "             'databases, DynamoDB, RDS, IAM, cost optimization, and resource '\n",
      "             'optimization. Here is a summary of the discussion:\\\\n\\\\n- '\n",
      "             '**Managed databases**: AWS offers a range of managed database '\n",
      "             'services, including DynamoDB, RDS, and Aurora. These services '\n",
      "             'make it easy to set up, manage, and scale databases without the '\n",
      "             'need for specialized expertise.\\\\n- **DynamoDB**: DynamoDB is a '\n",
      "             'scalable, low-latency NoSQL database service that is designed '\n",
      "             'for high-performance applications. It offers automatic scaling, '\n",
      "             'high availability, and built-in security features.\\\\n- **RDS**: '\n",
      "             'RDS is a fully managed relational database service that supports '\n",
      "             'a variety of database engines, including MySQL, PostgreSQL, and '\n",
      "             'Oracle. It offers automated backups, high availability, and '\n",
      "             'performance monitoring.\\\\n- **IAM**: IAM is a cloud-based '\n",
      "             'identity and access management service that helps you securely '\n",
      "             'control access to your AWS resources. It allows you to create '\n",
      "             'users, groups, and roles, and to assign permissions to these '\n",
      "             'entities.\\\\n- **Cost optimization**: AWS offers a variety of '\n",
      "             'tools and services to help you optimize your AWS costs. These '\n",
      "             'tools can help you identify and eliminate unused resources, '\n",
      "             'optimize your instance types and storage tiers, and take '\n",
      "             'advantage of discounts and pricing programs.\\\\n- **Resource '\n",
      "             'optimization**: Rightsizing your resources is important to '\n",
      "             'ensure that you are using the appropriate amount of resources '\n",
      "             'for your workload. AWS provides a variety of tools and services '\n",
      "             'to help you rightsize your resources, including the EC2 Instance '\n",
      "             'Advisor and the Auto Scaling service.\\\\n\\\\nOverall, the '\n",
      "             'conversation provides a comprehensive overview of AWS services '\n",
      "             \"and best practices.'}\",\n",
      "  'timestamp': '2024-10-08T21:20:48.552800'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'user', 'content': 'Hello'}\",\n",
      "  'timestamp': '2024-10-08T21:21:06.878195'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'assistant', 'content': 'I am sorry, but the provided \"\n",
      "             'context does not have the answer to your question. The context '\n",
      "             'focuses on a discussion about AWS services, database management, '\n",
      "             'and optimization strategies without any mention of \"Hello.\"\\'}',\n",
      "  'timestamp': '2024-10-08T21:21:06.881613'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'user', 'content': 'I am just saying hello'}\",\n",
      "  'timestamp': '2024-10-08T21:21:19.034013'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'assistant', 'content': 'I am sorry, but the provided \"\n",
      "             'context does not have the answer to your question. The context '\n",
      "             'focuses on a discussion about AWS services, database management, '\n",
      "             'and optimization strategies without any mention of \"Hello.\"\\'}',\n",
      "  'timestamp': '2024-10-08T21:21:19.037806'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'user', 'content': 'List the main AWS Services'}\",\n",
      "  'timestamp': '2024-10-08T21:21:34.184851'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'assistant', 'content': 'The main AWS services \"\n",
      "             'discussed in the conversation are:\\\\n- Managed databases, '\n",
      "             'including DynamoDB, RDS, and Aurora\\\\n- Identity and Access '\n",
      "             'Management (IAM)\\\\n- Cost optimization tools and services\\\\n- '\n",
      "             'Resource optimization tools and services, including the EC2 '\n",
      "             \"Instance Advisor and the Auto Scaling service'}\",\n",
      "  'timestamp': '2024-10-08T21:21:34.188278'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'user', 'content': 'What are the most important ones? \"\n",
      "             \"Only provide key points'}\",\n",
      "  'timestamp': '2024-10-08T21:21:54.062242'},\n",
      " {'batch_id': 3,\n",
      "  'content': \"{'role': 'assistant', 'content': '- **Managed databases**: AWS \"\n",
      "             'offers a range of managed database services, including DynamoDB, '\n",
      "             'RDS, and Aurora. These services make it easy to set up, manage, '\n",
      "             'and scale databases without the need for specialized '\n",
      "             'expertise.\\\\n- **IAM**: IAM is a cloud-based identity and access '\n",
      "             'management service that helps you securely control access to '\n",
      "             'your AWS resources. It allows you to create users, groups, and '\n",
      "             'roles, and to assign permissions to these entities.\\\\n- **Cost '\n",
      "             'optimization**: AWS offers a variety of tools and services to '\n",
      "             'help you optimize your AWS costs. These tools can help you '\n",
      "             'identify and eliminate unused resources, optimize your instance '\n",
      "             'types and storage tiers, and take advantage of discounts and '\n",
      "             'pricing programs.\\\\n- **Resource optimization**: Rightsizing '\n",
      "             'your resources is important to ensure that you are using the '\n",
      "             'appropriate amount of resources for your workload. AWS provides '\n",
      "             'a variety of tools and services to help you rightsize your '\n",
      "             'resources, including the EC2 Instance Advisor and the Auto '\n",
      "             \"Scaling service.'}\",\n",
      "  'timestamp': '2024-10-08T21:21:54.066755'}]\n"
     ]
    }
   ],
   "source": [
    "history = chat_manager.get_chat_history(\"user1\")\n",
    "pprint.pprint(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the cache is deleted and we want to rehydrate cache with previous 20 messages, we can call the below method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_manager.load_messages_from_dynamodb('user1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
